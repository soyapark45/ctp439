<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> Audio Visualization </title>
</head>
<body>		
	<h1> Mini Project #1: Loudness Mapping </h1>
	
	<input id="fileChooseInput" type="file"></input>
	<button onclick="playSound(myAudioBuffer)">Play</button>
	<button onclick="stopSound()">Stop</button>	  

	<p><canvas id='wave_view' style="background: white;"></canvas></p>

	<script>	
	var context;
	var myAudioBuffer = null;
	var analyser;
	
	var wave_view;
	var WIDTH = 512;
	var HEIGHT = 512;
	
	var amp_envelop = 0;

	//
	window.onload=function(){
		// file open button
		var control = document.getElementById("fileChooseInput");
		control.addEventListener("change", fileChanged, false);
		
		// canvas 
		wave_view = document.getElementById("wave_view");
		wave_view.width =  WIDTH;
		wave_view.height = HEIGHT;
		
		// create audio context
		context = new AudioContext();
		
		// analyzer
	    analyser = context.createAnalyser();
	    analyser.fftSize = 256;
		analyser.smoothingTimeConstant = 1;		
	}
	
	function draw_wave(timestamp) {		
		// 2d canvas context
		var drawContext = wave_view.getContext('2d');
		
		// fill rectangular
		drawContext.clearRect(0, 0, WIDTH, HEIGHT);
		drawContext.fillStyle = 'rgb(200, 200, 200)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
				
		// get samples 
		//frequencyBinCount = ftp size /2
		var dataArray = new Float32Array(analyser.frequencyBinCount);
		analyser.getFloatTimeDomainData(dataArray);
		
		// Your job is computing "amp_envelope" as a loudness measure
		//
		// 1) Compute the power of the time-domain samples (captured by the analyser node)
		//
		// 2) Convert the power to a log-scale level:  
		// 	  current_level = amp_scale*Math.log(1.0+1.0/sensitivity*power)/Math.log(1.0+1.0/sensitivity) 
		//
		//    Select appropriate values for amp_scale (e.g. 100) and sensitivity (e.g. 0.1)
		//
		// 3) Implement a simple envelope follower as below,
		//    3-1) amp_envelope = current_level,  if  current_level  > amp_envelope  (Attrack)
		//    3-1) amp_envelope = decay_coef* amp_envelope,  if  current_level  > amp_envelope (Decay)
		//        (decay_coef can be set to 0.9 or so)  
		
		///// YOUR CODE IS HERE /////

		/*
			The AnalyserNode interface represents a node able to provide real-time frequency and time-domain analysis information. It is an AudioNode that passes the audio stream unchanged from the input to the output, but allows you to take the generated data, process it, and create audio visualizations.
		*/
		var CANVAS_SIZE = 256;
		var window_size = context.sampleRate*0.02;  
		var hop = context.sampleRate*0.01;
		
		//Compute the RMS(min) and Max-peak(max) of the time-domain samples
		var RMS = true;

		// Display of RMS amplitude
		if (RMS) {
			for(var i = 0; i < dataArray.length; i++) {
				dataArray[i] = Math.pow(dataArray[i],2);
			}

			var mean = dataArray.reduce(function(a, b) { return a + b; }) / dataArray.length;

			power = Math.sqrt(mean);				
		}

		// Diplay peak amplitude
		else {
			for(var i = 0; i < dataArray.length; i++) {
				dataArray[i] = Math.abs(dataArray[i]);
			}

			power = Math.max.apply(null, dataArray);
		}
			
		amp_scale = 300;
		sensitivity = 0.01;
		decay_coef = 0.95;

		current_level = amp_scale*Math.log(1.0+1.0/sensitivity*power)/Math.log(1.0+1.0/sensitivity);

		// Attack
		if (current_level > amp_envelop)
		 	amp_envelop = current_level;

		// Decay
		if (current_level  <= amp_envelop)
			amp_envelop = decay_coef* amp_envelop;
		
		if (amp_envelop > CANVAS_SIZE)
			amp_envelop = CANVAS_SIZE;

		///////////////////////////


		// draw circle
		drawContext.beginPath();
		drawContext.arc(CANVAS_SIZE, CANVAS_SIZE, amp_envelop, 0, 2*Math.PI, true);
		drawContext.stroke();
		old_amp = amp_envelop;
				 
		// queue for next callback
		window.requestAnimationFrame(draw_wave);
	}

	function fileChanged(e){
		var file = e.target.files[0];
		var fileReader = new FileReader();
		fileReader.onload = fileLoaded;
		fileReader.readAsArrayBuffer(file);
	}

	function fileLoaded(e){
	    context.decodeAudioData(e.target.result, function(buffer) {
	      myAudioBuffer = buffer;
	    });
	}

	var source = null;
	function playSound(anybuffer) {
	  source = context.createBufferSource();
	  source.buffer = anybuffer;
	  source.connect(context.destination);
	  
	  // connect source to analyser
	  source.connect(analyser);
	  
	  source.start();
	  
	  // visualize audio
	  draw_wave();
	}

	function stopSound() {
	  if (source) {
	    source.stop();
	  }
	}	   	
	</script>
</body>
</html>
