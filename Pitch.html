<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> Audio Visualization </title>
</head>
<body>
	<h1> Mini Project #1: Pitch Tracking </h1>		
	
	<p><canvas id='spec_view' style="background: white;"></canvas></p>

	<script>	
	var context;
	var myAudioBuffer = null;
	var analyser;
	
	var spec_view;
	var WIDTH = 640;
	var HEIGHT = 320;
	
	
	// initial setting for pitch detection
	var PITCH_MIN = 36;
	var PITCH_MAX = 96;
	var PITCH_STEP = 0.25;
	var pitch_range = [];
	var pitch_range_hz = [];
	var NUM_HARMONICS = 15;	

	window.onload=function(){		
		// canvas 
		spec_view = document.getElementById("spec_view");
		spec_view.width =  WIDTH;
		spec_view.height = HEIGHT;	
		
		// create audio context
		context = new AudioContext();
		
		// analyzer
	    analyser = context.createAnalyser();
	    analyser.fftSize = 2048;
		analyser.smoothingTimeConstant = 0;		
		
		// pitch range of interest
		for (var pitch = PITCH_MIN; pitch <= PITCH_MAX; pitch = pitch + PITCH_STEP) 
		{
			pitch_range.push(pitch);
			pitch_range_hz.push(midi2hertz(pitch))
		}		
	}
	
	function midi2hertz(midi) {
		var hertz;
		///// YOUR CODE IS HERE /////
		
		
		
		
		/////////////////////////////
		return hertz;
	}
	
	function draw_spec() {
		// 2d canvas context
		var drawContext = spec_view.getContext('2d');
		
		// fill rectangular
		drawContext.fillStyle = 'rgb(200, 200, 200)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
		drawContext.beginPath();
				
		// get samples 
		var dataArray = new Float32Array(analyser.frequencyBinCount);
		analyser.getFloatFrequencyData(dataArray);
		
		var freq_scale = 10;
		var sliceWidth = WIDTH * 1.0 / (dataArray.length/freq_scale);
		var x = 0;

		// display spectrum up to Nyquist_Frequency/10
		for (var i = 0; i < dataArray.length/freq_scale; i++) {
	        var v = (dataArray[i] + 100)/50;
	        var y = HEIGHT - v * HEIGHT/2;

	    	if(i === 0) {
	        	drawContext.moveTo(x, y);
	        } else {
	        	drawContext.lineTo(x, y);
	        }

	        x += sliceWidth;
		}

		// last touch
		drawContext.lineTo(draw_spec.width, draw_spec.height/2);
		drawContext.stroke();

		//
		// pitch detection
		//
		// Refer to the stft_pitch.m file (MATLAB) to implement the pitch detection algorithm
		
		///// YOUR CODE IS HERE /////
		
		
		
		
		/////////////////////////////		

		drawContext.font = "30px Arial";
		if ( 1 )  // THIS SHOULD BE REPLACED WITH THE CONDITIONS FOR HARMONICITY AND ENERGY VALUES 
		{
			var detected_pitch_position = 40;   // THIS SHOULD BE REPLACED WITH DETECTED PITCH FROM THE CODE ABOVE
			drawContext.strokeText("-- Hz",100,50);
						
			drawContext.fillStyle = 'rgb(100,0,0)';
			drawContext.fillRect(detected_pitch_position, 0, 2, HEIGHT);
		}

		// queue for next callback
		window.requestAnimationFrame(draw_spec);
	}
	

	
	if (!navigator.getUserMedia)
		navigator.getUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
							  
	if (!navigator.getUserMedia)
		alert("Error: getUserMedia not supported!");
						
	// get audio input streaming 				 
	navigator.getUserMedia({audio: true}, onStream, onStreamError)

	// successCallback
	function onStream(stream) {
	    var input = context.createMediaStreamSource(stream);
		
		// Connect graph
		input.connect(analyser);
							  
		// visualize audio
		draw_spec();	
	}
	
	// errorCallback			 
	function onStreamError(error) {
		console.error('Error getting microphone', error);
	}

	</script>
</body>
</html>
